{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6e1806",
   "metadata": {},
   "source": [
    "# GPT pretraining\n",
    "\n",
    "Configuration:\n",
    "\n",
    "- `transformers` version: 4.11.0.dev0\n",
    "- Platform: Linux-4.15.0-124-generic-x86_64-with-Ubuntu-18.04-bionic\n",
    "- Python version: 3.6.9\n",
    "- PyTorch version (GPU?): 1.9.0+cu102 (True)\n",
    "- Tensorflow version (GPU?): not installed (NA)\n",
    "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
    "- Jax version: not installed\n",
    "- JaxLib version: not installed\n",
    "- Using GPU in script?: <fill in>\n",
    "- Using distributed or parallel set-up in script?: <fill in>\n",
    "- Deepspeed version:  0.5.3\n",
    "\n",
    "Docker image: in [dockerfile](./dockerfile)\n",
    "    \n",
    "## Torch DDP\n",
    "Training with distributed data parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9612954",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_8t27tbga/none_cqs182pr\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small/runs/Sep21_02-03-42_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "100%|############################################| 3/3 [00:00<00:00, 617.41it/s]\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 688.12it/s]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:03:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "100%|############################################| 3/3 [00:00<00:00, 692.05it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 709.62it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 739.87it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 799.63it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 849.16it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 815.22it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:43,921 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:43,922 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 02:03:44,232 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:44,535 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:44,536 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:46,960 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:46,961 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 02:03:47 - INFO - __main__ - Gradient checkpointing: False\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 02:03:50 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 02:03:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-870a216588541f22.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  80%|############   | 4/5 [00:00<00:00, 11.50ba/s][W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 14.05ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 02:03:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-9b57d268f8d3db79.arrow\n",
      "Running tokenizer on dataset:  46%|#####9       | 17/37 [00:00<00:01, 18.34ba/s][W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.38ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 02:03:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7bd856e591f0e9c5.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 22.96ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7a24fe661fb282d7.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.65ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 02:03:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5db29afbcf8ea071.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.14ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 02:04:10 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5d623869083674b6.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.49ba/s]\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 02:04:11,618 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 02:04:11,657 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 02:04:11,657 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 02:04:11,657 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 02:04:11,657 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 02:04:11,657 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 02:04:11,657 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 02:04:11,657 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "{'loss': 9.8518, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3083, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      "{'loss': 8.6652, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}        \n",
      "{'loss': 8.322, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}         \n",
      "{'loss': 8.149, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}          \n",
      "{'loss': 8.0654, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.55it/s][INFO|trainer.py:1391] 2021-09-21 02:04:35,615 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 23.9586, 'train_samples_per_second': 96.75, 'train_steps_per_second': 3.047, 'train_loss': 8.73206825778909, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.05it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-21 02:04:35,621 >> Saving model checkpoint to ./models/gpt2-small\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:04:35,628 >> Configuration saved in ./models/gpt2-small/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:04:45,296 >> Model weights saved in ./models/gpt2-small/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:04:45,531 >> tokenizer config file saved in ./models/gpt2-small/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:04:45,535 >> Special tokens file saved in ./models/gpt2-small/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.7321\n",
      "  train_runtime            = 0:00:23.95\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =      96.75\n",
      "  train_steps_per_second   =      3.047\n",
      "09/21/2021 02:04:45 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:04:45,760 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:04:45,760 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:04:45,760 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  3.60it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.9691\n",
      "  eval_runtime            = 0:00:01.13\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    211.659\n",
      "  eval_steps_per_second   =      3.528\n",
      "  perplexity              =  2890.3225\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00037288665771484375 seconds\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"18104\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 1, \"group_rank\": 0, \"worker_id\": \"18105\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [1], \\\"role_rank\\\": [1], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 2, \"group_rank\": 0, \"worker_id\": \"18106\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [2], \\\"role_rank\\\": [2], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 3, \"group_rank\": 0, \"worker_id\": \"18107\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [3], \\\"role_rank\\\": [3], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 4, \"group_rank\": 0, \"worker_id\": \"18108\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [4], \\\"role_rank\\\": [4], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 5, \"group_rank\": 0, \"worker_id\": \"18109\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [5], \\\"role_rank\\\": [5], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 6, \"group_rank\": 0, \"worker_id\": \"18110\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [6], \\\"role_rank\\\": [6], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 7, \"group_rank\": 0, \"worker_id\": \"18111\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [7], \\\"role_rank\\\": [7], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --save_total_limit=1 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --output_dir {} \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir\n",
    "\"\"\".format(LOG_DIR)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8b6f6",
   "metadata": {},
   "source": [
    "## DeepSpeed With CPU offloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d57e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepspeed-gpt2-small-V100.config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed-gpt2-small-V100.config.json\n",
    "\n",
    "{\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"_reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 100,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55d6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-23 04:09:45,533] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2021-09-23 04:09:45,896] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 my_run_clm.py --model_name_or_path gpt2 --dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train --do_eval --eval_steps=10 --logging_steps=10 --save_steps=50 --fp16=true --per_device_train_batch_size=4 --output_dir ./models/gpt2-small-deepspeed-V100 --save_total_limit=1 --num_train_epochs=1 --overwrite_output_dir=true --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.10.3\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=8, node_rank=0\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:102:main] dist_world_size=8\n",
      "[2021-09-23 04:09:46,545] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,060] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,434] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,482] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,522] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,554] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-23 04:09:48,575] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-23 04:09:48,600] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-23 04:09:48,614] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=deepspeed-gpt2-small-V100.config.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small-deepspeed-V100/runs/Sep23_04-09-48_dgx1v-loki-29,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small-deepspeed-V100,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small-deepspeed-V100,\n",
      "save_on_each_node=False,\n",
      "save_steps=50,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/23/2021 04:09:49 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 628.27it/s]\n",
      "09/23/2021 04:09:49 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 609.40it/s]\n",
      "09/23/2021 04:09:50 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/23/2021 04:09:50 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/23/2021 04:09:50 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/23/2021 04:09:50 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/23/2021 04:09:50 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/23/2021 04:09:50 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/23/2021 04:09:50 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/23/2021 04:09:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/23/2021 04:09:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/23/2021 04:09:50 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/23/2021 04:09:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "100%|############################################| 3/3 [00:00<00:00, 713.64it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 708.38it/s]\n",
      "09/23/2021 04:09:50 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 680.60it/s]\n",
      "09/23/2021 04:09:50 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 690.31it/s]\n",
      "09/23/2021 04:09:50 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 655.77it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-23 04:09:50,337 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-23 04:09:50,338 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-23 04:09:50,642 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-23 04:09:50,941 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-23 04:09:50,942 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,331 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,331 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,331 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,331 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,332 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-23 04:09:53,332 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-23 04:09:53,637 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-23 04:09:53,638 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/23/2021 04:09:54 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 754.73it/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/23/2021 04:09:57 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/23/2021 04:09:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-3922147a999e3c21.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 14.29ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/23/2021 04:09:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-9d20865d492c7c67.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 19.80ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/23/2021 04:09:59 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-1e3ecc79975727d1.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 21.95ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/23/2021 04:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/23/2021 04:10:06 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a67eb6679dd6c1a0.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.61ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/23/2021 04:10:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-6b13525cf6a6579d.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:13<00:00,  2.84ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/23/2021 04:10:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2fe86288484ebf38.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.14ba/s]\n",
      "[INFO|trainer.py:432] 2021-09-23 04:10:21,622 >> Using amp fp16 backend\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "[2021-09-23 04:10:21,627] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.3, git-hash=unknown, git-branch=unknown\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/23/2021 04:10:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[2021-09-23 04:10:22,759] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
      "[2021-09-23 04:10:22,759] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
      "[2021-09-23 04:10:22,896] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
      "[2021-09-23 04:10:22,897] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[2021-09-23 04:10:22,908] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
      "[2021-09-23 04:10:22,918] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [1]\n",
      "[2021-09-23 04:10:22,928] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [2]\n",
      "[2021-09-23 04:10:22,929] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [3]\n",
      "[2021-09-23 04:10:22,939] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [4]\n",
      "[2021-09-23 04:10:22,950] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [5]\n",
      "[2021-09-23 04:10:22,960] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [6]\n",
      "[2021-09-23 04:10:22,971] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [7]\n",
      "[2021-09-23 04:10:24,259] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0576179027557373 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.012192726135254 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0133256912231445 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0084044933319092 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0204980373382568 seconds\n",
      "Time to load cpu_adam op: 1.0458080768585205 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9883878231048584 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.1250545978546143 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2021-09-23 04:10:26,631] [INFO] [engine.py:823:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2021-09-23 04:10:26,637] [INFO] [engine.py:830:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2021-09-23 04:10:26,637] [INFO] [utils.py:44:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2021-09-23 04:10:26,637] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
      "[2021-09-23 04:10:26,637] [INFO] [stage2.py:111:__init__] Reduce bucket size 500000000\n",
      "[2021-09-23 04:10:26,638] [INFO] [stage2.py:112:__init__] Allgather bucket size 500000000\n",
      "[2021-09-23 04:10:26,638] [INFO] [stage2.py:113:__init__] CPU Offload: True\n",
      "[2021-09-23 04:10:26,638] [INFO] [stage2.py:114:__init__] Round robin gradient partitioning: False\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.4888150691986084 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5023190975189209 seconds\n",
      "Time to load utils op: 0.5027456283569336 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5023455619812012 seconds\n",
      "Time to load utils op: 0.5022265911102295 seconds\n",
      "Time to load utils op: 0.5020873546600342 seconds\n",
      "Time to load utils op: 0.5022039413452148 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5026800632476807 seconds\n",
      "Rank: 7 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 2 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 1 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 6 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 5 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 4 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 3 partition count [8] and sizes[(15554976, False)] \n",
      "Rank: 0 partition count [8] and sizes[(15554976, False)] \n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.003358602523803711 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0012853145599365234 seconds\n",
      "Time to load utils op: 0.002347707748413086 seconds\n",
      "[2021-09-23 04:10:28,600] [INFO] [utils.py:714:see_memory_usage] Before initializing optimizer states\n",
      "[2021-09-23 04:10:28,601] [INFO] [utils.py:719:see_memory_usage] MA 0.32 GB         Max_MA 0.32 GB         CA 0.49 GB         Max_CA 0 GB \n",
      "[2021-09-23 04:10:28,601] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 52.68 GB, percent = 10.5%\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0006282329559326172 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.000797271728515625 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0008928775787353516 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0004010200500488281 seconds\n",
      "[2021-09-23 04:10:28,726] [INFO] [utils.py:714:see_memory_usage] After initializing optimizer states\n",
      "[2021-09-23 04:10:28,727] [INFO] [utils.py:719:see_memory_usage] MA 0.32 GB         Max_MA 0.32 GB         CA 0.49 GB         Max_CA 0 GB \n",
      "[2021-09-23 04:10:28,727] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 52.66 GB, percent = 10.5%\n",
      "[2021-09-23 04:10:28,727] [INFO] [stage2.py:473:__init__] optimizer state initialized\n",
      "[2021-09-23 04:10:28,761] [INFO] [utils.py:714:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2021-09-23 04:10:28,762] [INFO] [utils.py:719:see_memory_usage] MA 0.32 GB         Max_MA 0.32 GB         CA 0.49 GB         Max_CA 0 GB \n",
      "[2021-09-23 04:10:28,762] [INFO] [utils.py:724:see_memory_usage] CPU Virtual Memory:  used = 52.66 GB, percent = 10.5%\n",
      "[2021-09-23 04:10:28,763] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2021-09-23 04:10:28,763] [INFO] [engine.py:546:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2021-09-23 04:10:28,763] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f436cd03ef0>\n",
      "[2021-09-23 04:10:28,763] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2021-09-23 04:10:28,763] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   amp_params ................... False\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-09-23 04:10:28,764] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   fp16_enabled ................. True\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   gradient_clipping ............ 1.0\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 65536\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-09-23 04:10:28,765] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   optimizer_name ............... adamw\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   scheduler_name ............... WarmupLR\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 0}\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   steps_per_print .............. 100\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   train_batch_size ............. 32\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-09-23 04:10:28,766] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-09-23 04:10:28,767] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-09-23 04:10:28,767] [INFO] [config.py:944:print]   world_size ................... 8\n",
      "[2021-09-23 04:10:28,767] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
      "[2021-09-23 04:10:28,767] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 2, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 5, \n",
      "        \"buffer_size\": 1.000000e+08, \n",
      "        \"max_in_cpu\": 1.000000e+09, \n",
      "        \"pin_memory\": true\n",
      "    }, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": true, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false, \n",
      "        \"pipeline\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": \"auto\", \n",
      "    \"param_persistence_threshold\": \"auto\", \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": true, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-09-23 04:10:28,768] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-09-23 04:10:28,768] [INFO] [config.py:944:print]   zero_optimization_stage ...... 2\n",
      "[2021-09-23 04:10:28,768] [INFO] [config.py:952:print]   json = {\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-05, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"_reduce_bucket_size\": \"auto\", \n",
      "        \"stage3_prefetch_bucket_size\": \"auto\", \n",
      "        \"stage3_param_persistence_threshold\": \"auto\", \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 100, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00037097930908203125 seconds\n",
      "[INFO|trainer.py:1186] 2021-09-23 04:10:28,769 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-23 04:10:28,769 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-23 04:10:28,769 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-23 04:10:28,769 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-23 04:10:28,769 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-23 04:10:28,769 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-23 04:10:28,769 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][2021-09-23 04:10:29,432] [INFO] [stage2.py:1634:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n",
      "  1%|6                                           | 1/73 [00:00<00:47,  1.52it/s][2021-09-23 04:10:29,666] [INFO] [stage2.py:1634:step] [deepspeed] fp16 dynamic loss scale overflow! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
      "{'loss': 10.2805, 'learning_rate': 5e-05, 'epoch': 0.14}                        \n",
      "{'loss': 9.3969, 'learning_rate': 5e-05, 'epoch': 0.27}                         \n",
      "{'loss': 8.9289, 'learning_rate': 5e-05, 'epoch': 0.41}                         \n",
      "{'loss': 8.5391, 'learning_rate': 5e-05, 'epoch': 0.55}                         \n",
      "{'loss': 7.9898, 'learning_rate': 5e-05, 'epoch': 0.68}                         \n",
      " 68%|#############################4             | 50/73 [00:18<00:08,  2.77it/s][INFO|trainer.py:1963] 2021-09-23 04:10:47,115 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100/checkpoint-50\n",
      "[INFO|configuration_utils.py:404] 2021-09-23 04:10:47,135 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-23 04:10:48,331 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-23 04:10:48,359 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-23 04:10:48,380 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/special_tokens_map.json\n",
      "[2021-09-23 04:10:48,676] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/mp_rank_00_model_states.pt\n",
      "[2021-09-23 04:10:54,290] [INFO] [engine.py:2424:_copy_recovery_script] creating recovery script ./models/gpt2-small-deepspeed-V100/checkpoint-50/zero_to_fp32.py\n",
      "[2021-09-23 04:10:54,497] [INFO] [engine.py:2438:_save_zero_checkpoint] zero checkpoint saved ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "{'loss': 7.6562, 'learning_rate': 5e-05, 'epoch': 0.82}                         \n",
      "{'loss': 7.4141, 'learning_rate': 5e-05, 'epoch': 0.96}                         \n",
      "100%|###########################################| 73/73 [00:34<00:00,  3.01it/s][INFO|trainer.py:1391] 2021-09-23 04:11:02,858 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 34.089, 'train_samples_per_second': 67.998, 'train_steps_per_second': 2.141, 'train_loss': 8.552493578767123, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:34<00:00,  2.14it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-23 04:11:02,874 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100\n",
      "[INFO|configuration_utils.py:404] 2021-09-23 04:11:02,888 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-23 04:11:04,171 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-23 04:11:04,416 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-23 04:11:04,429 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.5525\n",
      "  train_runtime            = 0:00:34.08\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     67.998\n",
      "  train_steps_per_second   =      2.141\n",
      "09/23/2021 04:11:04 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-23 04:11:04,653 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-23 04:11:04,653 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-23 04:11:04,653 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:00<00:00,  7.36it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.2266\n",
      "  eval_runtime            = 0:00:00.56\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    422.895\n",
      "  eval_steps_per_second   =      7.048\n",
      "  perplexity              =  1375.4861\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small-deepspeed-V100\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"deepspeed --num_gpus=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=50 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4\\\n",
    "    --output_dir {} \\\n",
    "    --save_total_limit=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir=true \\\n",
    "    --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
    "\"\"\".format(LOG_DIR)\n",
    "! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e91ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin   cuda-10.2  games\t  lib\t     man   share\n",
      "cuda  etc\t include  licensing  sbin  src\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbbeca-2c69-477a-abdb-88314a3604f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
