{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f1b9e-092b-4fbf-b226-510cbf6dedd8",
   "metadata": {},
   "source": [
    "# GPT pretraining\n",
    "\n",
    "Configuration:\n",
    "\n",
    "- `transformers` version: 4.11.0.dev0\n",
    "- Platform: Linux-4.15.0-124-generic-x86_64-with-Ubuntu-18.04-bionic\n",
    "- Python version: 3.6.9\n",
    "- PyTorch version (GPU?): 1.9.0+cu102 (True)\n",
    "- Tensorflow version (GPU?): not installed (NA)\n",
    "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
    "- Jax version: not installed\n",
    "- JaxLib version: not installed\n",
    "- Using GPU in script?: <fill in>\n",
    "- Using distributed or parallel set-up in script?: <fill in>\n",
    "- Deepspeed version:  0.5.3\n",
    "\n",
    "Docker image: in [dockerfile](./dockerfile)\n",
    "    \n",
    "## Torch DDP\n",
    "Training with distributed data parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c6f31-7a5e-4c25-a659-d2cb273aecd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_8t27tbga/none_cqs182pr\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_8t27tbga/none_cqs182pr/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small/runs/Sep21_02-03-42_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:42 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "100%|############################################| 3/3 [00:00<00:00, 617.41it/s]\n",
      "09/21/2021 02:03:43 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 688.12it/s]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:03:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "100%|############################################| 3/3 [00:00<00:00, 692.05it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 709.62it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 739.87it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 799.63it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 849.16it/s]\n",
      "09/21/2021 02:03:43 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 815.22it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:43,921 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:43,922 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 02:03:44,232 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:44,535 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:44,536 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:03:46,655 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:03:46,960 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:03:46,961 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 02:03:47 - INFO - __main__ - Gradient checkpointing: False\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 02:03:50 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 02:03:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-870a216588541f22.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  80%|############   | 4/5 [00:00<00:00, 11.50ba/s][W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 14.05ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 02:03:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-9b57d268f8d3db79.arrow\n",
      "Running tokenizer on dataset:  46%|#####9       | 17/37 [00:00<00:01, 18.34ba/s][W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.38ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 02:03:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7bd856e591f0e9c5.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 22.96ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:03:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7a24fe661fb282d7.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.65ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 02:03:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5db29afbcf8ea071.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.14ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 02:04:10 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5d623869083674b6.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.49ba/s]\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:04:11 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 02:04:11,618 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 02:04:11,657 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 02:04:11,657 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 02:04:11,657 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 02:04:11,657 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 02:04:11,657 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 02:04:11,657 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 02:04:11,657 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "{'loss': 9.8518, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3083, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      "{'loss': 8.6652, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}        \n",
      "{'loss': 8.322, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}         \n",
      "{'loss': 8.149, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}          \n",
      "{'loss': 8.0654, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.55it/s][INFO|trainer.py:1391] 2021-09-21 02:04:35,615 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 23.9586, 'train_samples_per_second': 96.75, 'train_steps_per_second': 3.047, 'train_loss': 8.73206825778909, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.05it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-21 02:04:35,621 >> Saving model checkpoint to ./models/gpt2-small\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:04:35,628 >> Configuration saved in ./models/gpt2-small/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:04:45,296 >> Model weights saved in ./models/gpt2-small/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:04:45,531 >> tokenizer config file saved in ./models/gpt2-small/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:04:45,535 >> Special tokens file saved in ./models/gpt2-small/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.7321\n",
      "  train_runtime            = 0:00:23.95\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =      96.75\n",
      "  train_steps_per_second   =      3.047\n",
      "09/21/2021 02:04:45 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:04:45,760 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:04:45,760 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:04:45,760 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  3.60it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.9691\n",
      "  eval_runtime            = 0:00:01.13\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    211.659\n",
      "  eval_steps_per_second   =      3.528\n",
      "  perplexity              =  2890.3225\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00037288665771484375 seconds\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"18104\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 1, \"group_rank\": 0, \"worker_id\": \"18105\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [1], \\\"role_rank\\\": [1], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 2, \"group_rank\": 0, \"worker_id\": \"18106\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [2], \\\"role_rank\\\": [2], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 3, \"group_rank\": 0, \"worker_id\": \"18107\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [3], \\\"role_rank\\\": [3], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 4, \"group_rank\": 0, \"worker_id\": \"18108\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [4], \\\"role_rank\\\": [4], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 5, \"group_rank\": 0, \"worker_id\": \"18109\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [5], \\\"role_rank\\\": [5], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 6, \"group_rank\": 0, \"worker_id\": \"18110\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [6], \\\"role_rank\\\": [6], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 7, \"group_rank\": 0, \"worker_id\": \"18111\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [7], \\\"role_rank\\\": [7], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 70, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --save_total_limit=1 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --output_dir {} \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir\n",
    "\"\"\".format(LOG_DIR)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3c969-cf7a-491e-b465-9b5ab5a48745",
   "metadata": {},
   "source": [
    "## DeepSpeed With CPU offloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549799b2-d677-457e-a4b2-72dd477885ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepspeed-gpt2-small-V100.config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed-gpt2-small-V100.config.json\n",
    "\n",
    "{\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 100,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709a119b-6d97-4802-8627-e07ee1d6ef45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-21 02:04:52,537] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2021-09-21 02:04:52,886] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 my_run_clm.py --model_name_or_path gpt2 --dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train --do_eval --eval_steps=10 --logging_steps=10 --save_steps=50 --fp16=true --per_device_train_batch_size=4 --output_dir ./models/gpt2-small-deepspeed-V100 --save_total_limit=1 --num_train_epochs=1 --overwrite_output_dir=true --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
      "[2021-09-21 02:04:53,510] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.10.3\n",
      "[2021-09-21 02:04:53,511] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n",
      "[2021-09-21 02:04:53,511] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=8, node_rank=0\n",
      "[2021-09-21 02:04:53,511] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
      "[2021-09-21 02:04:53,511] [INFO] [launch.py:102:main] dist_world_size=8\n",
      "[2021-09-21 02:04:53,511] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:04:55,274] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:04:55,370] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:04:55,431] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:04:55,537] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:04:55,539] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:04:55,582] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:04:55,592] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:04:55,596] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=deepspeed-gpt2-small-V100.config.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small-deepspeed-V100/runs/Sep21_02-04-55_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small-deepspeed-V100,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small-deepspeed-V100,\n",
      "save_on_each_node=False,\n",
      "save_steps=50,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:56 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 728.43it/s]\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 709.38it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 592.89it/s]\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 780.43it/s]\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 793.82it/s]\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 781.21it/s]\n",
      "09/21/2021 02:04:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 770.63it/s]\n",
      "09/21/2021 02:04:58 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 02:04:58 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:04:58 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 02:04:58 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 02:04:58 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 02:04:58 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:04:58 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 02:04:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:04:58 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:04:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "100%|############################################| 3/3 [00:00<00:00, 792.23it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:04:58,458 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:04:58,459 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 02:04:58,776 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:04:59,085 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:04:59,086 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,526 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,527 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,527 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,527 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,527 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:05:01,527 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:05:01,829 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:05:01,829 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 02:05:01 - INFO - __main__ - Gradient checkpointing: False\n",
      "[INFO|modeling_utils.py:492] 2021-09-21 02:05:01,909 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "09/21/2021 02:05:09 - INFO - __main__ - Training new model from scratch - Total size=0.00M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 02:05:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c8573e4a3fbba15c.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 17.89ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 02:05:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-eb96ddf93505c631.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 22.44ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 02:05:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-3c550d2433eab3fc.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 24.78ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:05:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5b29bab5dae3bdca.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.68ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 02:05:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-d2a8ec34441034d3.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.15ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 02:05:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cbf843d17ad35e12.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.52ba/s]\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 02:05:30,961 >> Using amp fp16 backend\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "[2021-09-21 02:05:30,965] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.3, git-hash=unknown, git-branch=unknown\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:05:30 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[2021-09-21 02:05:30,990] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
      "[2021-09-21 02:05:30,990] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
      "[2021-09-21 02:05:31,096] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
      "[2021-09-21 02:05:31,096] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[2021-09-21 02:05:31,107] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
      "[2021-09-21 02:05:31,117] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [1]\n",
      "[2021-09-21 02:05:31,117] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [2]\n",
      "[2021-09-21 02:05:31,128] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [3]\n",
      "[2021-09-21 02:05:31,138] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [4]\n",
      "[2021-09-21 02:05:31,149] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [5]\n",
      "[2021-09-21 02:05:31,149] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [6]\n",
      "[2021-09-21 02:05:31,160] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [7]\n",
      "[2021-09-21 02:05:32,302] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9950494766235352 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9191915988922119 seconds\n",
      "Time to load cpu_adam op: 0.9604024887084961 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9478528499603271 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9603915214538574 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0293359756469727 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 0.9635035991668701 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 1.0416007041931152 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2021-09-21 02:05:34,698] [INFO] [engine.py:823:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2021-09-21 02:05:34,703] [INFO] [engine.py:830:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2021-09-21 02:05:34,703] [INFO] [utils.py:44:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2021-09-21 02:05:34,703] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
      "Initializing ZeRO Stage 3\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 02:05:34,707] [INFO] [stage3.py:638:__init__] Reduce bucket size 589824\n",
      "[2021-09-21 02:05:34,708] [INFO] [stage3.py:639:__init__] Allgather bucket size 530841.6000000001\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.48950719833374023 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.30205225944519043 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.3018031120300293 seconds\n",
      "Time to load utils op: 0.30173301696777344 seconds\n",
      "Time to load utils op: 0.3017578125 seconds\n",
      "Time to load utils op: 0.30196452140808105 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.30182600021362305 seconds\n",
      "Time to load utils op: 0.30201220512390137 seconds\n",
      "[2021-09-21 02:05:35,295] [INFO] [stage3.py:830:__init__] optimizer state initialized\n",
      "[2021-09-21 02:05:35,385] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 02:05:35,385] [INFO] [engine.py:546:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 02:05:35,385] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fa09bd500b8>\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Time to load utils op: 0.0004258155822753906 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0003960132598876953 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Time to load utils op: 0.0004925727844238281 seconds\n",
      "[2021-09-21 02:05:35,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Time to load utils op: 0.0004582405090332031 seconds\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00044798851013183594 seconds\n",
      "Time to load utils op: 0.000400543212890625 seconds\n",
      "[2021-09-21 02:05:35,386] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "Time to load utils op: 0.00039124488830566406 seconds\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   amp_params ................... False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-09-21 02:05:35,388] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   fp16_enabled ................. True\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   gradient_clipping ............ 1.0\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 65536\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   optimizer_name ............... adamw\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-09-21 02:05:35,389] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   scheduler_name ............... WarmupLR\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 0}\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   steps_per_print .............. 100\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   train_batch_size ............. 32\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   world_size ................... 8\n",
      "[2021-09-21 02:05:35,390] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
      "[2021-09-21 02:05:35,391] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 3, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.898240e+05, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 5, \n",
      "        \"buffer_size\": 1.000000e+08, \n",
      "        \"max_in_cpu\": 1.000000e+09, \n",
      "        \"pin_memory\": true\n",
      "    }, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": true, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false, \n",
      "        \"pipeline\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.308416e+05, \n",
      "    \"param_persistence_threshold\": 7.680000e+03, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": true, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-09-21 02:05:35,391] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-09-21 02:05:35,391] [INFO] [config.py:944:print]   zero_optimization_stage ...... 3\n",
      "[2021-09-21 02:05:35,392] [INFO] [config.py:952:print]   json = {\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-05, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 5.898240e+05, \n",
      "        \"stage3_prefetch_bucket_size\": 5.308416e+05, \n",
      "        \"stage3_param_persistence_threshold\": 7.680000e+03, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 100, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0003287792205810547 seconds\n",
      "[INFO|trainer.py:1186] 2021-09-21 02:05:35,392 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 02:05:35,393 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 02:05:35,393 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 02:05:35,393 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 02:05:35,393 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 02:05:35,393 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 02:05:35,393 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][2021-09-21 02:05:36,399] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n",
      "  1%|6                                           | 1/73 [00:00<01:10,  1.01it/s][2021-09-21 02:05:36,936] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
      "  7%|###                                         | 5/73 [00:03<00:46,  1.48it/s][2021-09-21 02:05:39,461] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
      "{'loss': 315.4875, 'learning_rate': 5e-05, 'epoch': 0.14}                       \n",
      "{'loss': 103.3063, 'learning_rate': 5e-05, 'epoch': 0.27}                       \n",
      "{'loss': 65.9688, 'learning_rate': 5e-05, 'epoch': 0.41}                        \n",
      "{'loss': 55.7156, 'learning_rate': 5e-05, 'epoch': 0.55}                        \n",
      "{'loss': 48.9219, 'learning_rate': 5e-05, 'epoch': 0.68}                        \n",
      " 68%|#############################4             | 50/73 [00:32<00:14,  1.58it/s][INFO|trainer.py:1963] 2021-09-21 02:06:07,526 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100/checkpoint-50\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:06:07,539 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:06:08,454 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:06:08,461 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:06:08,466 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/special_tokens_map.json\n",
      "[2021-09-21 02:06:08,965] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-small-deepspeed-V100/checkpoint-50/pytorch_model.bin\n",
      "[2021-09-21 02:06:17,056] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "[2021-09-21 02:07:21,475] [INFO] [engine.py:2424:_copy_recovery_script] creating recovery script ./models/gpt2-small-deepspeed-V100/checkpoint-50/zero_to_fp32.py\n",
      "[2021-09-21 02:07:21,955] [INFO] [engine.py:2438:_save_zero_checkpoint] zero checkpoint saved ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "{'loss': 46.0875, 'learning_rate': 5e-05, 'epoch': 0.82}                        \n",
      "{'loss': 43.6875, 'learning_rate': 5e-05, 'epoch': 0.96}                        \n",
      "100%|###########################################| 73/73 [02:03<00:00,  1.57it/s][INFO|trainer.py:1391] 2021-09-21 02:07:38,733 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 123.3403, 'train_samples_per_second': 18.794, 'train_steps_per_second': 0.592, 'train_loss': 94.82491438356165, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [02:03<00:00,  1.69s/it]\n",
      "[INFO|trainer.py:1963] 2021-09-21 02:07:38,748 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:07:38,777 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:07:39,284 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:07:39,289 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:07:39,292 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/special_tokens_map.json\n",
      "[2021-09-21 02:07:39,704] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-small-deepspeed-V100/pytorch_model.bin\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =    94.8249\n",
      "  train_runtime            = 0:02:03.34\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     18.794\n",
      "  train_steps_per_second   =      0.592\n",
      "09/21/2021 02:07:48 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:07:48,453 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:07:48,453 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:07:48,453 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:00<00:00,  6.00it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =                    1.0\n",
      "  eval_loss               =                40.2812\n",
      "  eval_runtime            =             0:00:00.95\n",
      "  eval_samples            =                    240\n",
      "  eval_samples_per_second =                251.573\n",
      "  eval_steps_per_second   =                  4.193\n",
      "  perplexity              = 3.1183481393501114e+17\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small-deepspeed-V100\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"deepspeed --num_gpus=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=50 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4\\\n",
    "    --output_dir {} \\\n",
    "    --save_total_limit=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir=true \\\n",
    "    --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
    "\"\"\".format(LOG_DIR)\n",
    "! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19fb58-0a9c-4d6b-8c50-942186b71963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
