{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f1b9e-092b-4fbf-b226-510cbf6dedd8",
   "metadata": {},
   "source": [
    "# GPT pretraining\n",
    "\n",
    "Configuration:\n",
    "\n",
    "- `transformers` version: 4.11.0.dev0\n",
    "- Platform: Linux-4.15.0-124-generic-x86_64-with-Ubuntu-18.04-bionic\n",
    "- Python version: 3.6.9\n",
    "- PyTorch version (GPU?): 1.9.0+cu102 (True)\n",
    "- Tensorflow version (GPU?): not installed (NA)\n",
    "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
    "- Jax version: not installed\n",
    "- JaxLib version: not installed\n",
    "- Using GPU in script?: <fill in>\n",
    "- Using distributed or parallel set-up in script?: <fill in>\n",
    "- Deepspeed version:  0.5.3\n",
    "\n",
    "Docker image: in [dockerfile](./dockerfile)\n",
    "    \n",
    "## Torch DDP\n",
    "Training with distributed data parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c6f31-7a5e-4c25-a659-d2cb273aecd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_6yoy9api/none_vsrt_lbj/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small/runs/Sep21_01-10-52_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:10:52 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:10:52 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 694.57it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 727.59it/s]\n",
      "09/21/2021 01:10:52 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 01:10:52 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:10:52 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 01:10:52 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 01:10:52 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 01:10:52 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:10:52 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:10:52 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:10:52 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:10:52 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:10:52 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:10:52 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "100%|############################################| 3/3 [00:00<00:00, 660.97it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 682.33it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 703.07it/s]\n",
      "09/21/2021 01:10:53 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 682.67it/s]\n",
      "09/21/2021 01:10:53 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 743.01it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:10:53,309 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:10:53,310 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 01:10:53,616 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:10:53,917 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:10:53,917 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,056 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,057 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,057 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,057 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,057 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:10:56,057 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:10:56,361 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:10:56,362 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 01:10:57 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 916.99it/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:10:59 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s][W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:10:59 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-b23efa52e093a240.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  40%|######         | 2/5 [00:00<00:00, 15.15ba/s][W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 15.56ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 01:11:00 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-30571ead5d37e338.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.52ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 01:11:01 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-61fbf96d74ea449e.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 23.12ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  60%|#########      | 3/5 [00:00<00:00,  9.16ba/s]09/21/2021 01:11:14 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-84d20294eb25501e.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 11.03ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 10.61ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 10.13ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 10.02ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00,  9.47ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00,  9.46ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00,  9.46ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:02<00:00,  2.42ba/s]\n",
      "Running tokenizer on dataset:  54%|#######      | 20/37 [00:01<00:01,  9.88ba/s]09/21/2021 01:11:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-ffbfd5d26f4c0e9c.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 11.28ba/s]\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.57ba/s]\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.62ba/s]\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.66ba/s]\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.58ba/s]\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.47ba/s]\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 15.44ba/s]\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:03<00:00, 10.47ba/s]\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:11:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:13<00:00,  2.83ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 01:11:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7d8a1eef61f7cdd0.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.39ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s][INFO|trainer.py:432] 2021-09-21 01:11:30,229 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 01:11:30,262 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 01:11:30,262 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 01:11:30,262 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 01:11:30,262 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 01:11:30,262 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 01:11:30,262 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 01:11:30,262 >>   Total optimization steps = 73\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.84ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.78ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.77ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.76ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.70ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.68ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.64ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.23ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.17ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.09ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.05ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.05ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.03ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.02ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.45ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.39ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.40ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.42ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.40ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.35ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.36ba/s]\n",
      "{'loss': 9.8518, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3082, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      "{'loss': 8.6652, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}        \n",
      "{'loss': 8.322, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}         \n",
      "{'loss': 8.149, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}          \n",
      "{'loss': 8.0654, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [00:29<00:00,  2.86it/s][INFO|trainer.py:1391] 2021-09-21 01:12:14,188 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 43.9261, 'train_samples_per_second': 52.77, 'train_steps_per_second': 1.662, 'train_loss': 8.732065122421474, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:29<00:00,  2.51it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-21 01:12:14,194 >> Saving model checkpoint to ./models/gpt2-small\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 01:12:14,202 >> Configuration saved in ./models/gpt2-small/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 01:12:23,857 >> Model weights saved in ./models/gpt2-small/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 01:12:23,863 >> tokenizer config file saved in ./models/gpt2-small/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 01:12:23,867 >> Special tokens file saved in ./models/gpt2-small/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.7321\n",
      "  train_runtime            = 0:00:43.92\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =      52.77\n",
      "  train_steps_per_second   =      1.662\n",
      "09/21/2021 01:12:24 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 01:12:24,067 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 01:12:24,067 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 01:12:24,067 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  3.55it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.9691\n",
      "  eval_runtime            = 0:00:01.15\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    208.547\n",
      "  eval_steps_per_second   =      3.476\n",
      "  perplexity              =  2890.3239\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.000392913818359375 seconds\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"5103\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 1, \"group_rank\": 0, \"worker_id\": \"5104\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [1], \\\"role_rank\\\": [1], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 2, \"group_rank\": 0, \"worker_id\": \"5105\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [2], \\\"role_rank\\\": [2], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 3, \"group_rank\": 0, \"worker_id\": \"5106\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [3], \\\"role_rank\\\": [3], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 4, \"group_rank\": 0, \"worker_id\": \"5107\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [4], \\\"role_rank\\\": [4], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 5, \"group_rank\": 0, \"worker_id\": \"5108\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [5], \\\"role_rank\\\": [5], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 6, \"group_rank\": 0, \"worker_id\": \"5109\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [6], \\\"role_rank\\\": [6], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 7, \"group_rank\": 0, \"worker_id\": \"5110\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [7], \\\"role_rank\\\": [7], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 100, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --save_total_limit=1 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --output_dir {} \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir\n",
    "\"\"\".format(LOG_DIR)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3c969-cf7a-491e-b465-9b5ab5a48745",
   "metadata": {},
   "source": [
    "## DeepSpeed With CPU offloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549799b2-d677-457e-a4b2-72dd477885ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepspeed-gpt2-small-V100.config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed-gpt2-small-V100.config.json\n",
    "\n",
    "{\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 100,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709a119b-6d97-4802-8627-e07ee1d6ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-21 01:33:40,206] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2021-09-21 01:33:40,541] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 my_run_clm.py --model_name_or_path gpt2 --dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train --do_eval --eval_steps=10 --logging_steps=10 --save_steps=50 --fp16=true --per_device_train_batch_size=4 --output_dir ./models/gpt2-medium-deepspeed-a100 --save_total_limit=1 --num_train_epochs=1 --overwrite_output_dir=true --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
      "[2021-09-21 01:33:41,200] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.10.3\n",
      "[2021-09-21 01:33:41,200] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n",
      "[2021-09-21 01:33:41,200] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=8, node_rank=0\n",
      "[2021-09-21 01:33:41,201] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
      "[2021-09-21 01:33:41,201] [INFO] [launch.py:102:main] dist_world_size=8\n",
      "[2021-09-21 01:33:41,201] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 01:33:42,949] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 01:33:43,116] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 01:33:43,194] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 01:33:43,210] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 01:33:43,216] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 01:33:43,228] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 01:33:43,239] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 01:33:43,239] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=deepspeed-gpt2-small-V100.config.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-medium-deepspeed-a100/runs/Sep21_01-33-42_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-medium-deepspeed-a100,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-medium-deepspeed-a100,\n",
      "save_on_each_node=False,\n",
      "save_steps=50,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:43 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:33:44 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 01:33:44 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:33:44 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 01:33:44 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 01:33:44 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 01:33:44 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:33:44 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 01:33:44 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:33:44 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 673.13it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 675.38it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 816.97it/s]\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 785.89it/s]\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 655.87it/s]\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 701.62it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 589.53it/s]\n",
      "09/21/2021 01:33:44 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 785.79it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:33:44,415 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:33:44,416 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 01:33:44,718 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:33:45,022 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:33:45,023 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,170 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,170 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,170 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,170 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,171 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:33:47,171 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:33:47,471 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:33:47,471 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:492] 2021-09-21 01:33:47,556 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "09/21/2021 01:33:55 - INFO - __main__ - Training new model from scratch - Total size=0.00M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 01:33:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-0cac474698ffe090.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 18.64ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 01:33:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-4ce4d9627ad0881b.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 23.54ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 01:33:59 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-61aeca61295a4eea.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 23.82ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:33:59 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c61a415d73a7c476.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.63ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 01:34:00 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-0388885f71862834.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.15ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 01:34:12 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-59323ac1b0776169.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.61ba/s]\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 01:34:13,475 >> Using amp fp16 backend\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[2021-09-21 01:34:13,480] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.3, git-hash=unknown, git-branch=unknown\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:34:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[2021-09-21 01:34:13,507] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
      "[2021-09-21 01:34:13,507] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
      "[2021-09-21 01:34:13,591] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
      "[2021-09-21 01:34:13,601] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[2021-09-21 01:34:13,612] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
      "[2021-09-21 01:34:13,623] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [1]\n",
      "[2021-09-21 01:34:13,633] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [2]\n",
      "[2021-09-21 01:34:13,644] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [3]\n",
      "[2021-09-21 01:34:13,655] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [4]\n",
      "[2021-09-21 01:34:13,655] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [5]\n",
      "[2021-09-21 01:34:13,666] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [6]\n",
      "[2021-09-21 01:34:13,676] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [7]\n",
      "[2021-09-21 01:34:14,821] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/cpu_adam...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.6/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/adam/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
      "[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.6/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.6/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -L/usr/local/cuda/lib64 -lcudart -lcublas -g -Wno-reorder -march=native -fopenmp -D__AVX256__ -c /usr/local/lib/python3.6/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
      "[3/3] c++ cpu_adam.o custom_cuda_kernel.cuda.o -shared -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o cpu_adam.so\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 21.292209148406982 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 21.25907254219055 seconds\n",
      "Time to load cpu_adam op: 21.269482612609863 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 21.293193817138672 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 21.295283794403076 seconds\n",
      "Time to load cpu_adam op: 21.334859609603882 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 21.305795192718506 seconds\n",
      "Time to load cpu_adam op: 21.305000066757202 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2021-09-21 01:34:37,417] [INFO] [engine.py:823:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2021-09-21 01:34:37,421] [INFO] [engine.py:830:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2021-09-21 01:34:37,422] [INFO] [utils.py:44:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2021-09-21 01:34:37,422] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
      "Initializing ZeRO Stage 3\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 01:34:37,427] [INFO] [stage3.py:638:__init__] Reduce bucket size 589824\n",
      "[2021-09-21 01:34:37,427] [INFO] [stage3.py:639:__init__] Allgather bucket size 530841.6000000001\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.49186182022094727 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5020973682403564 seconds\n",
      "Time to load utils op: 0.5021982192993164 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5036189556121826 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5023431777954102 seconds\n",
      "Time to load utils op: 0.5020802021026611 seconds\n",
      "Time to load utils op: 0.5021305084228516 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5023789405822754 seconds\n",
      "[2021-09-21 01:34:38,298] [INFO] [stage3.py:830:__init__] optimizer state initialized\n",
      "[2021-09-21 01:34:38,435] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2021-09-21 01:34:38,435] [INFO] [engine.py:546:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2021-09-21 01:34:38,435] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f0cf2184048>\n",
      "[2021-09-21 01:34:38,435] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 01:34:38,435] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00043702125549316406 seconds\n",
      "Time to load utils op: 0.0004398822784423828 seconds\n",
      "Time to load utils op: 0.00043964385986328125 seconds\n",
      "Time to load utils op: 0.00044035911560058594 seconds\n",
      "Time to load utils op: 0.00042176246643066406 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0004012584686279297 seconds\n",
      "Time to load utils op: 0.000766754150390625 seconds\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   amp_params ................... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-09-21 01:34:38,439] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   fp16_enabled ................. True\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   gradient_clipping ............ 1.0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 65536\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   optimizer_name ............... adamw\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   scheduler_name ............... WarmupLR\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 0}\n",
      "[2021-09-21 01:34:38,440] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   steps_per_print .............. 100\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   train_batch_size ............. 32\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   world_size ................... 8\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 3, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.898240e+05, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 5, \n",
      "        \"buffer_size\": 1.000000e+08, \n",
      "        \"max_in_cpu\": 1.000000e+09, \n",
      "        \"pin_memory\": true\n",
      "    }, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": true, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false, \n",
      "        \"pipeline\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.308416e+05, \n",
      "    \"param_persistence_threshold\": 7.680000e+03, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": true, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-09-21 01:34:38,441] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-09-21 01:34:38,442] [INFO] [config.py:944:print]   zero_optimization_stage ...... 3\n",
      "[2021-09-21 01:34:38,442] [INFO] [config.py:952:print]   json = {\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-05, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 5.898240e+05, \n",
      "        \"stage3_prefetch_bucket_size\": 5.308416e+05, \n",
      "        \"stage3_param_persistence_threshold\": 7.680000e+03, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 100, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0003254413604736328 seconds\n",
      "[INFO|trainer.py:1186] 2021-09-21 01:34:38,443 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 01:34:38,443 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 01:34:38,443 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 01:34:38,443 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 01:34:38,443 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 01:34:38,443 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 01:34:38,443 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][2021-09-21 01:34:39,193] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n",
      "  1%|6                                           | 1/73 [00:00<00:53,  1.36it/s][2021-09-21 01:34:39,827] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
      "  7%|###                                         | 5/73 [00:03<00:52,  1.30it/s][2021-09-21 01:34:42,874] [INFO] [stage3.py:2735:_overflow_clean_up] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
      "{'loss': 315.4875, 'learning_rate': 5e-05, 'epoch': 0.14}                       \n",
      "{'loss': 103.3063, 'learning_rate': 5e-05, 'epoch': 0.27}                       \n",
      "{'loss': 65.9688, 'learning_rate': 5e-05, 'epoch': 0.41}                        \n",
      "{'loss': 55.7156, 'learning_rate': 5e-05, 'epoch': 0.55}                        \n",
      "{'loss': 48.9219, 'learning_rate': 5e-05, 'epoch': 0.68}                        \n",
      " 68%|#############################4             | 50/73 [00:38<00:17,  1.31it/s][INFO|trainer.py:1963] 2021-09-21 01:35:16,631 >> Saving model checkpoint to ./models/gpt2-medium-deepspeed-a100/checkpoint-50\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 01:35:16,846 >> Configuration saved in ./models/gpt2-medium-deepspeed-a100/checkpoint-50/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 01:35:17,228 >> Model weights saved in ./models/gpt2-medium-deepspeed-a100/checkpoint-50/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 01:35:17,234 >> tokenizer config file saved in ./models/gpt2-medium-deepspeed-a100/checkpoint-50/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 01:35:17,238 >> Special tokens file saved in ./models/gpt2-medium-deepspeed-a100/checkpoint-50/special_tokens_map.json\n",
      "[2021-09-21 01:35:17,696] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-medium-deepspeed-a100/checkpoint-50/pytorch_model.bin\n",
      "[2021-09-21 01:35:25,510] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./models/gpt2-medium-deepspeed-a100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "[2021-09-21 01:35:46,271] [INFO] [engine.py:2424:_copy_recovery_script] creating recovery script ./models/gpt2-medium-deepspeed-a100/checkpoint-50/zero_to_fp32.py\n",
      "[2021-09-21 01:35:46,343] [INFO] [engine.py:2438:_save_zero_checkpoint] zero checkpoint saved ./models/gpt2-medium-deepspeed-a100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "{'loss': 46.0875, 'learning_rate': 5e-05, 'epoch': 0.82}                        \n",
      "{'loss': 43.6875, 'learning_rate': 5e-05, 'epoch': 0.96}                        \n",
      "100%|###########################################| 73/73 [01:25<00:00,  1.41it/s][INFO|trainer.py:1391] 2021-09-21 01:36:04,366 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 85.9232, 'train_samples_per_second': 26.978, 'train_steps_per_second': 0.85, 'train_loss': 94.82491438356165, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [01:25<00:00,  1.18s/it]\n",
      "[INFO|trainer.py:1963] 2021-09-21 01:36:04,379 >> Saving model checkpoint to ./models/gpt2-medium-deepspeed-a100\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 01:36:04,384 >> Configuration saved in ./models/gpt2-medium-deepspeed-a100/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 01:36:04,599 >> Model weights saved in ./models/gpt2-medium-deepspeed-a100/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 01:36:04,604 >> tokenizer config file saved in ./models/gpt2-medium-deepspeed-a100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 01:36:04,607 >> Special tokens file saved in ./models/gpt2-medium-deepspeed-a100/special_tokens_map.json\n",
      "[2021-09-21 01:36:04,928] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-medium-deepspeed-a100/pytorch_model.bin\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =    94.8249\n",
      "  train_runtime            = 0:01:25.92\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     26.978\n",
      "  train_steps_per_second   =       0.85\n",
      "09/21/2021 01:36:08 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 01:36:08,335 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 01:36:08,336 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 01:36:08,336 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:00<00:00,  5.67it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =                    1.0\n",
      "  eval_loss               =                40.2812\n",
      "  eval_runtime            =             0:00:00.98\n",
      "  eval_samples            =                    240\n",
      "  eval_samples_per_second =                244.052\n",
      "  eval_steps_per_second   =                  4.068\n",
      "  perplexity              = 3.1183481393501114e+17\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-medium-deepspeed-a100\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"deepspeed --num_gpus=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=50 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4\\\n",
    "    --output_dir {} \\\n",
    "    --save_total_limit=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir=true \\\n",
    "    --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
    "\"\"\".format(LOG_DIR)\n",
    "! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19fb58-0a9c-4d6b-8c50-942186b71963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
