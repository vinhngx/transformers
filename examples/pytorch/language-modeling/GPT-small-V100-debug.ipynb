{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f1b9e-092b-4fbf-b226-510cbf6dedd8",
   "metadata": {},
   "source": [
    "# GPT pretraining\n",
    "\n",
    "Configuration:\n",
    "\n",
    "- `transformers` version: 4.11.0.dev0\n",
    "- Platform: Linux-4.15.0-124-generic-x86_64-with-Ubuntu-18.04-bionic\n",
    "- Python version: 3.6.9\n",
    "- PyTorch version (GPU?): 1.9.0+cu102 (True)\n",
    "- Tensorflow version (GPU?): not installed (NA)\n",
    "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
    "- Jax version: not installed\n",
    "- JaxLib version: not installed\n",
    "- Using GPU in script?: <fill in>\n",
    "- Using distributed or parallel set-up in script?: <fill in>\n",
    "- Deepspeed version:  0.5.3\n",
    "\n",
    "Docker image: in [dockerfile](./dockerfile)\n",
    "    \n",
    "## Torch DDP\n",
    "Training with distributed data parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c6f31-7a5e-4c25-a659-d2cb273aecd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small/runs/Sep21_01-59-07_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 685.16it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 731.65it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 727.59it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 682.11it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 679.17it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 688.61it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 734.34it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 746.23it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:08,559 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:08,560 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 01:59:08,870 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:09,179 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:09,180 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:11,620 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:11,621 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 01:59:11 - INFO - __main__ - Gradient checkpointing: False\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:59:14 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s][W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:59:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-19e0b969d4d91be6.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  40%|######         | 2/5 [00:00<00:00, 14.72ba/s][W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 14.94ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 01:59:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-8221520c7fe380a8.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.77ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 01:59:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-073474533135a57d.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 22.07ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-28d186b04a3c8bd5.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.88ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 01:59:23 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c7960195783c8bcd.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.22ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 01:59:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-63007a769eab766f.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.59ba/s]\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 01:59:35,939 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 01:59:35,977 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 01:59:35,977 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 01:59:35,977 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 01:59:35,977 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 01:59:35,977 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 01:59:35,977 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 01:59:35,977 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "{'loss': 9.8518, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3083, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      "{'loss': 8.6652, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}        \n",
      "{'loss': 8.322, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}         \n",
      "{'loss': 8.149, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}          \n",
      "{'loss': 8.0654, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.55it/s][INFO|trainer.py:1391] 2021-09-21 01:59:59,788 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 23.8108, 'train_samples_per_second': 97.351, 'train_steps_per_second': 3.066, 'train_loss': 8.73206825778909, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.07it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-21 01:59:59,794 >> Saving model checkpoint to ./models/gpt2-small\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 01:59:59,806 >> Configuration saved in ./models/gpt2-small/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:00:13,104 >> Model weights saved in ./models/gpt2-small/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:00:13,110 >> tokenizer config file saved in ./models/gpt2-small/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:00:13,115 >> Special tokens file saved in ./models/gpt2-small/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.7321\n",
      "  train_runtime            = 0:00:23.81\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     97.351\n",
      "  train_steps_per_second   =      3.066\n",
      "09/21/2021 02:00:13 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:00:13,350 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:00:13,350 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:00:13,350 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  2.86it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.9691\n",
      "  eval_runtime            = 0:00:01.15\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    207.601\n",
      "  eval_steps_per_second   =       3.46\n",
      "  perplexity              =  2890.3225\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00039315223693847656 seconds\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"16490\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 1, \"group_rank\": 0, \"worker_id\": \"16491\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [1], \\\"role_rank\\\": [1], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 2, \"group_rank\": 0, \"worker_id\": \"16492\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [2], \\\"role_rank\\\": [2], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 3, \"group_rank\": 0, \"worker_id\": \"16493\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [3], \\\"role_rank\\\": [3], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 4, \"group_rank\": 0, \"worker_id\": \"16494\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [4], \\\"role_rank\\\": [4], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 5, \"group_rank\": 0, \"worker_id\": \"16495\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [5], \\\"role_rank\\\": [5], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 6, \"group_rank\": 0, \"worker_id\": \"16496\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [6], \\\"role_rank\\\": [6], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 7, \"group_rank\": 0, \"worker_id\": \"16497\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [7], \\\"role_rank\\\": [7], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --save_total_limit=1 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --output_dir {} \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir\n",
    "\"\"\".format(LOG_DIR)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3c969-cf7a-491e-b465-9b5ab5a48745",
   "metadata": {},
   "source": [
    "## DeepSpeed With CPU offloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549799b2-d677-457e-a4b2-72dd477885ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepspeed-gpt2-small-V100.config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed-gpt2-small-V100.config.json\n",
    "\n",
    "{\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 100,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709a119b-6d97-4802-8627-e07ee1d6ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-21 02:00:21,725] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2021-09-21 02:00:22,081] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 my_run_clm.py --model_name_or_path gpt2 --dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train --do_eval --eval_steps=10 --logging_steps=10 --save_steps=50 --fp16=true --per_device_train_batch_size=4 --output_dir ./models/gpt2-small-deepspeed-V100 --save_total_limit=1 --num_train_epochs=1 --overwrite_output_dir=true --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.10.3\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=8, node_rank=0\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:102:main] dist_world_size=8\n",
      "[2021-09-21 02:00:22,751] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:00:24,279] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:00:24,626] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:00:24,650] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:00:24,664] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:00:24,697] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "[2021-09-21 02:00:24,740] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:00:24,743] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "[2021-09-21 02:00:24,745] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=deepspeed-gpt2-small-V100.config.json,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small-deepspeed-V100/runs/Sep21_02-00-24_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small-deepspeed-V100,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small-deepspeed-V100,\n",
      "save_on_each_node=False,\n",
      "save_steps=50,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:24 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 833.58it/s]\n",
      "09/21/2021 02:00:25 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 02:00:25 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:00:25 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 02:00:25 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 02:00:25 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 02:00:25 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:00:25 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 02:00:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 02:00:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 664.92it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 678.87it/s]\n",
      "09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 665.87it/s]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 884.94it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 895.77it/s]\n",
      "09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 02:00:25 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 873.51it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 810.08it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:00:25,590 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:00:25,591 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 02:00:25,895 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:00:26,200 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:00:26,200 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 02:00:28,338 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 02:00:28,640 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 02:00:28,641 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 02:00:28 - INFO - __main__ - Gradient checkpointing: False\n",
      "[INFO|modeling_utils.py:492] 2021-09-21 02:00:28,734 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "09/21/2021 02:00:33 - INFO - __main__ - Training new model from scratch - Total size=0.00M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 02:00:38 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5eff21e38b1bd1e.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 18.53ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 02:00:39 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-57a9645fdf157319.arrow\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 25.68ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 02:00:40 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-30afa6eb161f08cc.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 28.25ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 02:00:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-ff8cb57c59bf2942.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.80ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 02:00:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-ad32b45aae65cfb4.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.06ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 02:00:54 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-f9250c5265523b0c.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.37ba/s]\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 02:00:55,274 >> Using amp fp16 backend\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 02:00:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|deepspeed.py:334] 2021-09-21 02:00:55,277 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)\n",
      "[2021-09-21 02:00:55,285] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.3, git-hash=unknown, git-branch=unknown\n",
      "[2021-09-21 02:00:55,311] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
      "[2021-09-21 02:00:55,311] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
      "[2021-09-21 02:00:55,406] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
      "[2021-09-21 02:00:55,406] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[2021-09-21 02:00:55,427] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
      "[2021-09-21 02:00:55,428] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [1]\n",
      "[2021-09-21 02:00:55,438] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [2]\n",
      "[2021-09-21 02:00:55,448] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [3]\n",
      "[2021-09-21 02:00:55,449] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [4]\n",
      "[2021-09-21 02:00:55,459] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [5]\n",
      "[2021-09-21 02:00:55,470] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [6]\n",
      "[2021-09-21 02:00:55,480] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [7]\n",
      "[2021-09-21 02:00:56,727] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
      "[2021-09-21 02:00:56,727] [INFO] [engine.py:808:_configure_optimizer] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2021-09-21 02:00:56,727] [INFO] [engine.py:813:_configure_optimizer] Using client Optimizer as basic optimizer\n",
      "[2021-09-21 02:00:56,731] [INFO] [engine.py:830:_configure_optimizer] DeepSpeed Basic Optimizer = AdamW\n",
      "[2021-09-21 02:00:56,731] [INFO] [utils.py:44:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>\n",
      "[2021-09-21 02:00:56,731] [WARNING] [engine.py:840:_configure_optimizer] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n",
      "[2021-09-21 02:00:56,731] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\n",
      "Initializing ZeRO Stage 3\n",
      "[2021-09-21 02:00:56,735] [INFO] [stage3.py:638:__init__] Reduce bucket size 589824\n",
      "[2021-09-21 02:00:56,735] [INFO] [stage3.py:639:__init__] Allgather bucket size 530841.6000000001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.5006577968597412 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.40274667739868164 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.40217161178588867 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.40241265296936035 seconds\n",
      "Time to load utils op: 0.4020967483520508 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.402496337890625 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.40234875679016113 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.4022684097290039 seconds\n",
      "[2021-09-21 02:00:58,295] [INFO] [stage3.py:830:__init__] optimizer state initialized\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 02:00:58,429] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0004391670227050781 seconds\n",
      "Time to load utils op: 0.0004367828369140625 seconds\n",
      "Time to load utils op: 0.0004401206970214844 seconds\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00047278404235839844 seconds\n",
      "Time to load utils op: 0.0004851818084716797 seconds\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "[2021-09-21 02:00:58,430] [INFO] [engine.py:555:_configure_lr_scheduler] DeepSpeed using client LR scheduler\n",
      "Time to load utils op: 0.0005466938018798828 seconds\n",
      "[2021-09-21 02:00:58,430] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f1234de58d0>\n",
      "[2021-09-21 02:00:58,430] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "[2021-09-21 02:00:58,430] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
      "Time to load utils op: 0.0007822513580322266 seconds\n",
      "[2021-09-21 02:00:58,433] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   amp_params ................... False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   dump_state ................... False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... None\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
      "[2021-09-21 02:00:58,434] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   fp16_enabled ................. False\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   global_rank .................. 0\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   gradient_clipping ............ 1.0\n",
      "[2021-09-21 02:00:58,435] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 4294967296\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   optimizer_name ............... None\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   optimizer_params ............. None\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   pld_params ................... False\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
      "[2021-09-21 02:00:58,436] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   scheduler_name ............... None\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   scheduler_params ............. None\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   steps_per_print .............. 100\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   train_batch_size ............. 32\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   world_size ................... 8\n",
      "[2021-09-21 02:00:58,437] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  True\n",
      "[2021-09-21 02:00:58,439] [INFO] [config.py:944:print]   zero_config .................. {\n",
      "    \"stage\": 3, \n",
      "    \"contiguous_gradients\": true, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.898240e+05, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": true, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": true, \n",
      "    \"offload_param\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 5, \n",
      "        \"buffer_size\": 1.000000e+08, \n",
      "        \"max_in_cpu\": 1.000000e+09, \n",
      "        \"pin_memory\": true\n",
      "    }, \n",
      "    \"offload_optimizer\": {\n",
      "        \"device\": \"cpu\", \n",
      "        \"nvme_path\": null, \n",
      "        \"buffer_count\": 4, \n",
      "        \"pin_memory\": true, \n",
      "        \"pipeline_read\": false, \n",
      "        \"pipeline_write\": false, \n",
      "        \"fast_init\": false, \n",
      "        \"pipeline\": false\n",
      "    }, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.308416e+05, \n",
      "    \"param_persistence_threshold\": 7.680000e+03, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_fp16_weights_on_model_save\": true, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false\n",
      "}\n",
      "[2021-09-21 02:00:58,439] [INFO] [config.py:944:print]   zero_enabled ................. True\n",
      "[2021-09-21 02:00:58,439] [INFO] [config.py:944:print]   zero_optimization_stage ...... 3\n",
      "[2021-09-21 02:00:58,439] [INFO] [config.py:952:print]   json = {\n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 5.898240e+05, \n",
      "        \"stage3_prefetch_bucket_size\": 5.308416e+05, \n",
      "        \"stage3_param_persistence_threshold\": 7.680000e+03, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 100, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0005133152008056641 seconds\n",
      "[INFO|trainer.py:1186] 2021-09-21 02:00:58,440 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 02:00:58,440 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 02:00:58,440 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 02:00:58,440 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 02:00:58,440 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 02:00:58,441 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 02:00:58,441 >>   Total optimization steps = 73\n",
      "{'loss': 228.1229, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}      \n",
      "{'loss': 81.5364, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}         \n",
      "{'loss': 61.6822, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}        \n",
      "{'loss': 55.3642, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}       \n",
      "{'loss': 50.8445, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}       \n",
      " 68%|#############################4             | 50/73 [00:47<00:21,  1.06it/s][INFO|trainer.py:1963] 2021-09-21 02:01:46,085 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100/checkpoint-50\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:01:46,095 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:01:46,475 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:01:46,480 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:01:46,484 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/checkpoint-50/special_tokens_map.json\n",
      "[2021-09-21 02:01:47,110] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-small-deepspeed-V100/checkpoint-50/pytorch_model.bin\n",
      "[2021-09-21 02:02:04,079] [INFO] [logging.py:68:log_dist] [Rank 0] Saving model checkpoint: ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "[2021-09-21 02:02:46,606] [INFO] [engine.py:2424:_copy_recovery_script] creating recovery script ./models/gpt2-small-deepspeed-V100/checkpoint-50/zero_to_fp32.py\n",
      "[2021-09-21 02:02:46,967] [INFO] [engine.py:2438:_save_zero_checkpoint] zero checkpoint saved ./models/gpt2-small-deepspeed-V100/checkpoint-50/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "{'loss': 48.8636, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}        \n",
      "{'loss': 47.759, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [02:11<00:00,  1.16it/s][INFO|trainer.py:1391] 2021-09-21 02:03:09,817 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 131.3771, 'train_samples_per_second': 17.644, 'train_steps_per_second': 0.556, 'train_loss': 80.61621888043129, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [02:11<00:00,  1.80s/it]\n",
      "[INFO|trainer.py:1963] 2021-09-21 02:03:09,846 >> Saving model checkpoint to ./models/gpt2-small-deepspeed-V100\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 02:03:09,874 >> Configuration saved in ./models/gpt2-small-deepspeed-V100/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:03:10,252 >> Model weights saved in ./models/gpt2-small-deepspeed-V100/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:03:10,261 >> tokenizer config file saved in ./models/gpt2-small-deepspeed-V100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:03:10,268 >> Special tokens file saved in ./models/gpt2-small-deepspeed-V100/special_tokens_map.json\n",
      "[2021-09-21 02:03:10,812] [INFO] [engine.py:2539:save_fp16_model] Saving model weights to ./models/gpt2-small-deepspeed-V100/pytorch_model.bin\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =    80.6162\n",
      "  train_runtime            = 0:02:11.37\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     17.644\n",
      "  train_steps_per_second   =      0.556\n",
      "09/21/2021 02:03:25 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:03:25,042 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:03:25,042 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:03:25,042 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  3.54it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =                   1.0\n",
      "  eval_loss               =               45.1302\n",
      "  eval_runtime            =            0:00:01.57\n",
      "  eval_samples            =                   240\n",
      "  eval_samples_per_second =               152.043\n",
      "  eval_steps_per_second   =                 2.534\n",
      "  perplexity              = 3.979344064349233e+19\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small-deepspeed-V100\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"deepspeed --num_gpus=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=50 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4\\\n",
    "    --output_dir {} \\\n",
    "    --save_total_limit=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir=true \\\n",
    "    --deepspeed=deepspeed-gpt2-small-V100.config.json\n",
    "\"\"\".format(LOG_DIR)\n",
    "! $cmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
