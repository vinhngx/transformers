{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f1b9e-092b-4fbf-b226-510cbf6dedd8",
   "metadata": {},
   "source": [
    "# GPT pretraining\n",
    "\n",
    "Configuration:\n",
    "\n",
    "- `transformers` version: 4.11.0.dev0\n",
    "- Platform: Linux-4.15.0-124-generic-x86_64-with-Ubuntu-18.04-bionic\n",
    "- Python version: 3.6.9\n",
    "- PyTorch version (GPU?): 1.9.0+cu102 (True)\n",
    "- Tensorflow version (GPU?): not installed (NA)\n",
    "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
    "- Jax version: not installed\n",
    "- JaxLib version: not installed\n",
    "- Using GPU in script?: <fill in>\n",
    "- Using distributed or parallel set-up in script?: <fill in>\n",
    "- Deepspeed version:  0.5.3\n",
    "\n",
    "Docker image: in [dockerfile](./dockerfile)\n",
    "    \n",
    "## Torch DDP\n",
    "Training with distributed data parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c6f31-7a5e-4c25-a659-d2cb273aecd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_1numvsj5/none_ll6ck2a_/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small/runs/Sep21_01-59-07_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:07 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 01:59:08 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:59:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 685.16it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 731.65it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 727.59it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 682.11it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 679.17it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 688.61it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 734.34it/s]\n",
      "09/21/2021 01:59:08 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 746.23it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:08,559 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:08,560 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 01:59:08,870 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:09,179 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:09,180 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 01:59:11,310 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 01:59:11,620 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 01:59:11,621 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 01:59:11 - INFO - __main__ - Gradient checkpointing: False\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:59:14 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s][W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "09/21/2021 01:59:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-19e0b969d4d91be6.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  40%|######         | 2/5 [00:00<00:00, 14.72ba/s][W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 14.94ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 01:59:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-8221520c7fe380a8.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.77ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 01:59:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-073474533135a57d.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 22.07ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 01:59:21 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-28d186b04a3c8bd5.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.88ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 01:59:23 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c7960195783c8bcd.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:11<00:00,  3.22ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 01:59:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-63007a769eab766f.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.59ba/s]\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 01:59:35 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 01:59:35,939 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 01:59:35,977 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 01:59:35,977 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 01:59:35,977 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 01:59:35,977 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 01:59:35,977 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 01:59:35,977 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 01:59:35,977 >>   Total optimization steps = 73\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s][W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "{'loss': 9.8518, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3083, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      "{'loss': 8.6652, 'learning_rate': 2.2602739726027396e-05, 'epoch': 0.55}        \n",
      "{'loss': 8.322, 'learning_rate': 1.5753424657534248e-05, 'epoch': 0.68}         \n",
      "{'loss': 8.149, 'learning_rate': 8.904109589041095e-06, 'epoch': 0.82}          \n",
      "{'loss': 8.0654, 'learning_rate': 2.054794520547945e-06, 'epoch': 0.96}         \n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.55it/s][INFO|trainer.py:1391] 2021-09-21 01:59:59,788 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 23.8108, 'train_samples_per_second': 97.351, 'train_steps_per_second': 3.066, 'train_loss': 8.73206825778909, 'epoch': 1.0}\n",
      "100%|###########################################| 73/73 [00:23<00:00,  3.07it/s]\n",
      "[INFO|trainer.py:1963] 2021-09-21 01:59:59,794 >> Saving model checkpoint to ./models/gpt2-small\n",
      "[INFO|configuration_utils.py:404] 2021-09-21 01:59:59,806 >> Configuration saved in ./models/gpt2-small/config.json\n",
      "[INFO|modeling_utils.py:1013] 2021-09-21 02:00:13,104 >> Model weights saved in ./models/gpt2-small/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2033] 2021-09-21 02:00:13,110 >> tokenizer config file saved in ./models/gpt2-small/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2039] 2021-09-21 02:00:13,115 >> Special tokens file saved in ./models/gpt2-small/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     8.7321\n",
      "  train_runtime            = 0:00:23.81\n",
      "  train_samples            =       2318\n",
      "  train_samples_per_second =     97.351\n",
      "  train_steps_per_second   =      3.066\n",
      "09/21/2021 02:00:13 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:2209] 2021-09-21 02:00:13,350 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2211] 2021-09-21 02:00:13,350 >>   Num examples = 240\n",
      "[INFO|trainer.py:2214] 2021-09-21 02:00:13,350 >>   Batch size = 8\n",
      "100%|#############################################| 4/4 [00:01<00:00,  2.86it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     7.9691\n",
      "  eval_runtime            = 0:00:01.15\n",
      "  eval_samples            =        240\n",
      "  eval_samples_per_second =    207.601\n",
      "  eval_steps_per_second   =       3.46\n",
      "  perplexity              =  2890.3225\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00039315223693847656 seconds\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"16490\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 1, \"group_rank\": 0, \"worker_id\": \"16491\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [1], \\\"role_rank\\\": [1], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 2, \"group_rank\": 0, \"worker_id\": \"16492\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [2], \\\"role_rank\\\": [2], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 3, \"group_rank\": 0, \"worker_id\": \"16493\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [3], \\\"role_rank\\\": [3], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 4, \"group_rank\": 0, \"worker_id\": \"16494\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [4], \\\"role_rank\\\": [4], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 5, \"group_rank\": 0, \"worker_id\": \"16495\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [5], \\\"role_rank\\\": [5], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 6, \"group_rank\": 0, \"worker_id\": \"16496\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [6], \\\"role_rank\\\": [6], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 7, \"group_rank\": 0, \"worker_id\": \"16497\", \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [7], \\\"role_rank\\\": [7], \\\"role_world_size\\\": [8]}\", \"agent_restarts\": 0}}\n",
      "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"dgx1v-loki-21.nvidia.com\", \"state\": \"SUCCEEDED\", \"total_run_time\": 75, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --save_total_limit=1 \\\n",
    "    --fp16=true \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --output_dir {} \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir\n",
    "\"\"\".format(LOG_DIR)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3c969-cf7a-491e-b465-9b5ab5a48745",
   "metadata": {},
   "source": [
    "## Fairscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcbbe6b-ddeb-44d6-b574-93ef0fcee53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairscale\n",
      "  Downloading fairscale-0.4.0.tar.gz (190 kB)\n",
      "\u001b[K     |################################| 190 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fairscale) (1.9.0+cu102)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fairscale) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fairscale) (0.8)\n",
      "Building wheels for collected packages: fairscale\n",
      "  Building wheel for fairscale (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239949 sha256=1fd96ac812138a8062b1b960ad118deeabbd952fde38085e49d4e634c0f4299b\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/e1/47/7a55668000b72046246579e3b20b5cec7cbc580138973a7843\n",
      "Successfully built fairscale\n",
      "Installing collected packages: fairscale\n",
      "Successfully installed fairscale-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fairscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a119b-6d97-4802-8627-e07ee1d6ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
      " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
      "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
      "  entrypoint       : my_run_clm.py\n",
      "  min_nodes        : 1\n",
      "  max_nodes        : 1\n",
      "  nproc_per_node   : 8\n",
      "  run_id           : none\n",
      "  rdzv_backend     : static\n",
      "  rdzv_endpoint    : 127.0.0.1:29500\n",
      "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "  max_restarts     : 3\n",
      "  monitor_interval : 5\n",
      "  log_dir          : None\n",
      "  metrics_cfg      : {}\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
      "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
      "  restart_count=0\n",
      "  master_addr=127.0.0.1\n",
      "  master_port=29500\n",
      "  group_rank=0\n",
      "  group_world_size=1\n",
      "  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]\n",
      "\n",
      "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/0/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/1/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/2/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/3/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/4/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/5/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/6/error.json\n",
      "INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_ywaehjjr/none_2ohwosp0/attempt_0/7/error.json\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "Deepspeed version:  0.5.3\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 4, device: cuda:4, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=10,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=None,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./models/gpt2-small-fairscale-V100/runs/Sep21_04-22-19_dgx1v-loki-21,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "output_dir=./models/gpt2-small-fairscale-V100,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./models/gpt2-small-fairscale-V100,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[<ShardedDDPOption.SIMPLE: 'simple'>],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 5, device: cuda:5, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 7, device: cuda:7, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:19 - WARNING - __main__ - Process rank: 6, device: cuda:6, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 684.75it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 699.13it/s]\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 770.68it/s]\n",
      "09/21/2021 04:22:20 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext\n",
      "09/21/2021 04:22:20 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 04:22:20 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.py\n",
      "09/21/2021 04:22:20 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/dataset_infos.json\n",
      "09/21/2021 04:22:20 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/wikitext/wikitext.py at /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/wikitext.json\n",
      "09/21/2021 04:22:20 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 04:22:20 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "09/21/2021 04:22:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 04:22:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 724.20it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 706.03it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 747.20it/s]\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "09/21/2021 04:22:20 - WARNING - datasets.builder - Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|############################################| 3/3 [00:00<00:00, 762.65it/s]\n",
      "100%|############################################| 3/3 [00:00<00:00, 783.01it/s]\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 04:22:20,964 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 04:22:20,965 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:333] 2021-09-21 04:22:21,270 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 04:22:21,575 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 04:22:21,576 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,706 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,707 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,707 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,707 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,707 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2021-09-21 04:22:23,707 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:574] 2021-09-21 04:22:24,011 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "[INFO|configuration_utils.py:611] 2021-09-21 04:22:24,012 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "09/21/2021 04:22:24 - INFO - __main__ - Gradient checkpointing: False\n",
      "09/21/2021 04:22:27 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "Running tokenizer on dataset:   0%|                       | 0/5 [00:00<?, ?ba/s]09/21/2021 04:22:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-4e51b27e5a473639.arrow\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 4 using best-guess GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset:  40%|######         | 2/5 [00:00<00:00, 10.62ba/s][W ProcessGroupNCCL.cpp:1569] Rank 2 using best-guess GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 7 using best-guess GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 3 using best-guess GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|###############| 5/5 [00:00<00:00, 16.31ba/s]\n",
      "Running tokenizer on dataset:   0%|                      | 0/37 [00:00<?, ?ba/s]09/21/2021 04:22:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-b5585ba562ac0752.arrow\n",
      "Running tokenizer on dataset:  84%|##########8  | 31/37 [00:01<00:00, 20.77ba/s][W ProcessGroupNCCL.cpp:1569] Rank 6 using best-guess GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Running tokenizer on dataset: 100%|#############| 37/37 [00:01<00:00, 20.49ba/s]\n",
      "Running tokenizer on dataset:   0%|                       | 0/4 [00:00<?, ?ba/s]09/21/2021 04:22:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-5e281e96ee493c0d.arrow\n",
      "Running tokenizer on dataset: 100%|###############| 4/4 [00:00<00:00, 14.91ba/s]\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "[W ProcessGroupNCCL.cpp:1569] Rank 5 using best-guess GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/5 [00:00<?, ?ba/s]09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-2266f7484cadb60a.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-a5bc06eb2e64a1d8.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-c4174006a21be557.arrow\n",
      "09/21/2021 04:22:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-0f3a26665c7d8b08.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 5/5 [00:01<00:00,  3.74ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                  | 0/37 [00:00<?, ?ba/s]09/21/2021 04:22:37 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-99ddbdf90366d726.arrow\n",
      "Grouping texts in chunks of 1024: 100%|#########| 37/37 [00:12<00:00,  3.05ba/s]\n",
      "Grouping texts in chunks of 1024:   0%|                   | 0/4 [00:00<?, ?ba/s]09/21/2021 04:22:49 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-6c6205d288f9fd5a.arrow\n",
      "Grouping texts in chunks of 1024: 100%|###########| 4/4 [00:01<00:00,  3.39ba/s]\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-af571898e520659d.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-e7b3600fb8703320.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "09/21/2021 04:22:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-cd4accd885ea3649.arrow\n",
      "[INFO|trainer.py:432] 2021-09-21 04:22:51,357 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:1186] 2021-09-21 04:22:51,388 >> ***** Running training *****\n",
      "[INFO|trainer.py:1187] 2021-09-21 04:22:51,388 >>   Num examples = 2318\n",
      "[INFO|trainer.py:1188] 2021-09-21 04:22:51,388 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1189] 2021-09-21 04:22:51,388 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1190] 2021-09-21 04:22:51,388 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1191] 2021-09-21 04:22:51,388 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1192] 2021-09-21 04:22:51,388 >>   Total optimization steps = 73\n",
      "{'loss': 9.8519, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.14}        \n",
      "{'loss': 9.3082, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.27}          \n",
      "{'loss': 8.9365, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.41}         \n",
      " 53%|######################9                    | 39/73 [00:12<00:10,  3.25it/s]"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./models/gpt2-small-fairscale-V100\"\n",
    "!rm -rf $LOG_DIR\n",
    "cmd = \"\"\"python3  -m torch.distributed.launch --nproc_per_node=8 my_run_clm.py \\\n",
    "    --model_name_or_path gpt2 \\\n",
    "    --dataset_name wikitext \\\n",
    "    --dataset_config_name wikitext-2-raw-v1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --eval_steps=10 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=200 \\\n",
    "    --fp16=true \\\n",
    "    --sharded_ddp simple  \\\n",
    "    --per_device_train_batch_size=4\\\n",
    "    --output_dir {} \\\n",
    "    --save_total_limit=1 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --overwrite_output_dir=true\n",
    "\"\"\".format(LOG_DIR)\n",
    "! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb061f78-d322-44d9-89c7-65ee10273c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
